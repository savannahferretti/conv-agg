{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7570552e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5d2137-9303-4c3b-a46f-2f29a24154b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab8391",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## User-Defined Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7278a208-47ba-45b7-ae52-58d60aa073d0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "author = # 'your name'\n",
    "email  = # 'your email'\n",
    "path   = # '/directory/where/small/or/large/domain/files/are/located/'\n",
    "simset = 'rcemip-small' # or 'rcemip-large'\n",
    "dirout = 'massflux'\n",
    "cases  = ['nz_32','nz_64','nz_128','nz_256']\n",
    "today  = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35d0f80d-0588-4765-9e81-9299ef213988",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = path+simset\n",
    "if simset == 'rcemip-small':\n",
    "    dx = 780\n",
    "    outstr = '_99km_300K_'\n",
    "    nxny   = '_128_'\n",
    "else:\n",
    "    cases = cases[:2]\n",
    "    dx = 3_000\n",
    "    outstr = '_1536km_300K_'\n",
    "    nxny   = '_512_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b15ec",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Calculate and Save Mass Flux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2534507f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Calculate density following $\\rho = \\frac{p}{RT}$, then calculate mass flux of each column following $M = \\rho w$. Store $M$ in Xarray.Datasets by case, and save as netCDF files to ```dirout```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5dd9a23-c862-4d7e-a657-7223da765260",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i,case in enumerate(cases):\n",
    "    ## Check to See if Directory Exists\n",
    "    try: os.mkdir(path+case+'/OUT_3D/'+dirout)\n",
    "    except: print('Error: directory already exists')\n",
    "    print('Working on '+case+'...')    \n",
    "    ## List Files\n",
    "    pfile   = glob.glob(path+case'/OUT_3D/p/*.nc')[0]\n",
    "    wfiles  = np.sort(glob.glob(path+case+'/OUT_3D/W/*.nc'))\n",
    "    tfiles  = np.sort(glob.glob(path+case+'/OUT_3D/TABS/*.nc'))\n",
    "    ppfiles = np.sort(glob.glob(path+case+'/OUT_3D/PP/*.nc'))\n",
    "    for j in range(len(wfiles)):\n",
    "        timestr = wfiles[i][-13:-3]\n",
    "        ## Check to See if File Exists\n",
    "        filename = (path+case+'/OUT_3D/'+dirout+'/RCE_'+simset+outstr+case+nxny+dirout+'_'+timestr+'.nc')\n",
    "        if os.path.exists(filename): \n",
    "            print('Error: file already exists and will be skipped')\n",
    "            continue\n",
    "        ## Define Variables\n",
    "        p_background = xr.open_dataset(gpfile[j]).p*100 # from hPa to Pa\n",
    "        p = xr.load_dataset(ppfiles[j]).PP + p_background\n",
    "        w = xr.load_dataset(wfiles[j]).W\n",
    "        T = xr.load_dataset(tfiles[j]).TABS\n",
    "        ## Calculate Density\n",
    "        R = 287\n",
    "        rho = p/(R*T)\n",
    "        del T\n",
    "        del p\n",
    "        ## Calculate Mass Flux\n",
    "        M = rho*w\n",
    "        M.attrs['long_name'] = 'Mass flux'\n",
    "        M.attrs['units'] = '$kg m^{-2} s^{-1}$'\n",
    "        del rho\n",
    "        del w\n",
    "        ## Create Dataset and Save as a NetCDF File\n",
    "        print('Creating and saving dataset to: '+filename)\n",
    "        ds = xr.Dataset(data_vars=dict(M=M),attrs=dict(history='Calculated on '+today+' by '+author+': '+email))\n",
    "        ds.to_netcdf(filename)\n",
    "        del M\n",
    "        del ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conv-agg",
   "language": "python",
   "name": "conv-agg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
